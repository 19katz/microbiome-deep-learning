{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from itertools import cycle, product\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg') # this suppresses the console for plotting  \n",
    "import seaborn as sns\n",
    "\n",
    "# import private scripts\n",
    "import load_kmer_cnts_jf\n",
    "import stats_utils_AEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories (make sure date exists)\n",
    "date = 'testing_120418/'\n",
    "output_dir = os.environ['HOME'] + '/deep_learning_microbiome/analysis/kmers/linear/' + str(date)\n",
    "\n",
    "\n",
    "# filter out warnings about convergence \n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "kmer_size = None\n",
    "cv_gridsearch = None # number of folds for grid search\n",
    "cv_testfolds = None # number of folds for actual training of the best model\n",
    "n_iter = None # number of iterations of cross-validation\n",
    "random_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data sets to be tested\n",
    "# Each item consists of two lists: from the first, the healthy samples will be extracted.\n",
    "# From the second, diseased samples will be extracted.\n",
    "# The two sets will then be combined. \n",
    "data_sets_to_use = [\n",
    "    [['MetaHIT'], ['MetaHIT']],\n",
    "    [['Qin_et_al'], ['Qin_et_al']],\n",
    "    #[['Zeller_2014'], ['Zeller_2014']],\n",
    "    #[['LiverCirrhosis'], ['LiverCirrhosis']],\n",
    "    #[['Karlsson_2013_no_adapter'], ['Karlsson_2013_no_adapter']],\n",
    "    #[['RA_no_adapter'], ['RA_no_adapter']],\n",
    "    #[['LeChatelier'], ['LeChatelier']],\n",
    "    #[['Feng'], ['Feng']]\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of parameters for each model \n",
    "param_dict = {       \n",
    "    \"rf\": {\"n_estimators\": [400],\n",
    "           \"criterion\": [\"gini\"],\n",
    "           \"max_features\": [\"sqrt\"],\n",
    "           \"max_depth\": [None],\n",
    "           \"min_samples_split\": [2],\n",
    "           \"n_jobs\": [1]},\n",
    "    \"lassoLR\": {\"penalty\": [\"l1\"], \n",
    "                \"solver\": [\"saga\", \"liblinear\"]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From figuring out target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to help run it in jupyter #\n",
    "kmer_size = 5\n",
    "n_factor = 5\n",
    "###\n",
    "\n",
    "for data_set in data_sets_to_use:\n",
    "    data_set = data_set[0]\n",
    "        \n",
    "    # Retrieve diseased data and labels\n",
    "    allowed_labels = ['0', '1']\n",
    "    kmer_cnts, accessions, labelz, domain_labels = load_kmer_cnts_jf.load_kmers(kmer_size, data_set, allowed_labels)\n",
    "    print(\"LOADED DATASET \" + str(data_set[0]) + \": \" + str(len(kmer_cnts)) + \" SAMPLES\")\n",
    "    labelz=np.asarray(labelz).astype(np.int)\n",
    "    \n",
    "    for n in [0]:\n",
    "        if n == 0:\n",
    "            data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "            data_normalized, labels = shuffle(data_normalized, labelz, random_state=0) \n",
    "            x = data_normalized\n",
    "            y = labels\n",
    "                    \n",
    "        else:\n",
    "            data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "            data_normalized = stats_utils_AEB.NMF_factor(data_normalized, kmer_size, n_components = int(n), \n",
    "                                                     title=(str(data_set) + str(kmer_size) + \"mers\" \n",
    "                                                            + str(n) + \"factors\"))\n",
    "            data_normalized, labels = shuffle(data_normalized, labelz, random_state=0)\n",
    "            x = data_normalized\n",
    "            y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(targets)\n",
    "print(counts)\n",
    "print(counts[1]/(counts[1] + counts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to help run it in jupyter #\n",
    "learn_type = 'rf'\n",
    "cv_gridsearch = 10\n",
    "n_iter_grid = 1\n",
    "#n_splits = 5\n",
    "#n_repeats = 1\n",
    "\n",
    "###\n",
    "\n",
    "param_grid = param_dict[learn_type]\n",
    "\n",
    "scoring = {\n",
    "    'Acc': 'accuracy',\n",
    "    'AUC': 'roc_auc',\n",
    "    'F1': 'f1', # weighted average of precision and recall\n",
    "    'Precision': 'precision',\n",
    "    'Recall': 'recall'\n",
    "}\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2, n_jobs=1)\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=cv_gridsearch, n_repeats=n_iter_grid)\n",
    "grid_search = GridSearchCV(estimator, param_grid, cv = k_fold, n_jobs = 1, scoring=scoring, refit = False)\n",
    "grid_search = grid_search.fit(x, y)            \n",
    "grid_search_results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_Acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_Precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_Recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.31941969]),\n",
       " 'std_fit_time': array([0.02139739]),\n",
       " 'mean_score_time': array([0.11171954]),\n",
       " 'std_score_time': array([0.02184605]),\n",
       " 'param_criterion': masked_array(data=['gini'],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[None],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt'],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[400],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_jobs': masked_array(data=[1],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'n_jobs': 1}],\n",
       " 'split0_test_Acc': array([0.45714286]),\n",
       " 'split1_test_Acc': array([0.54285714]),\n",
       " 'split2_test_Acc': array([0.6]),\n",
       " 'split3_test_Acc': array([0.65714286]),\n",
       " 'split4_test_Acc': array([0.61764706]),\n",
       " 'split5_test_Acc': array([0.52941176]),\n",
       " 'split6_test_Acc': array([0.41176471]),\n",
       " 'split7_test_Acc': array([0.52941176]),\n",
       " 'split8_test_Acc': array([0.61764706]),\n",
       " 'split9_test_Acc': array([0.58823529]),\n",
       " 'mean_test_Acc': array([0.55523256]),\n",
       " 'std_test_Acc': array([0.07279412]),\n",
       " 'rank_test_Acc': array([1], dtype=int32),\n",
       " 'split0_train_Acc': array([1.]),\n",
       " 'split1_train_Acc': array([1.]),\n",
       " 'split2_train_Acc': array([1.]),\n",
       " 'split3_train_Acc': array([1.]),\n",
       " 'split4_train_Acc': array([1.]),\n",
       " 'split5_train_Acc': array([1.]),\n",
       " 'split6_train_Acc': array([1.]),\n",
       " 'split7_train_Acc': array([1.]),\n",
       " 'split8_train_Acc': array([1.]),\n",
       " 'split9_train_Acc': array([1.]),\n",
       " 'mean_train_Acc': array([1.]),\n",
       " 'std_train_Acc': array([0.]),\n",
       " 'split0_test_AUC': array([0.41013072]),\n",
       " 'split1_test_AUC': array([0.51797386]),\n",
       " 'split2_test_AUC': array([0.60457516]),\n",
       " 'split3_test_AUC': array([0.62745098]),\n",
       " 'split4_test_AUC': array([0.55882353]),\n",
       " 'split5_test_AUC': array([0.54152249]),\n",
       " 'split6_test_AUC': array([0.3633218]),\n",
       " 'split7_test_AUC': array([0.55017301]),\n",
       " 'split8_test_AUC': array([0.5449827]),\n",
       " 'split9_test_AUC': array([0.62456747]),\n",
       " 'mean_test_AUC': array([0.53441822]),\n",
       " 'std_test_AUC': array([0.08232013]),\n",
       " 'rank_test_AUC': array([1], dtype=int32),\n",
       " 'split0_train_AUC': array([1.]),\n",
       " 'split1_train_AUC': array([1.]),\n",
       " 'split2_train_AUC': array([1.]),\n",
       " 'split3_train_AUC': array([1.]),\n",
       " 'split4_train_AUC': array([1.]),\n",
       " 'split5_train_AUC': array([1.]),\n",
       " 'split6_train_AUC': array([1.]),\n",
       " 'split7_train_AUC': array([1.]),\n",
       " 'split8_train_AUC': array([1.]),\n",
       " 'split9_train_AUC': array([1.]),\n",
       " 'mean_train_AUC': array([1.]),\n",
       " 'std_train_AUC': array([4.96506831e-17]),\n",
       " 'split0_test_F1': array([0.45714286]),\n",
       " 'split1_test_F1': array([0.5]),\n",
       " 'split2_test_F1': array([0.61111111]),\n",
       " 'split3_test_F1': array([0.625]),\n",
       " 'split4_test_F1': array([0.60606061]),\n",
       " 'split5_test_F1': array([0.52941176]),\n",
       " 'split6_test_F1': array([0.44444444]),\n",
       " 'split7_test_F1': array([0.57894737]),\n",
       " 'split8_test_F1': array([0.58064516]),\n",
       " 'split9_test_F1': array([0.5625]),\n",
       " 'mean_test_F1': array([0.54951223]),\n",
       " 'std_test_F1': array([0.06106172]),\n",
       " 'rank_test_F1': array([1], dtype=int32),\n",
       " 'split0_train_F1': array([1.]),\n",
       " 'split1_train_F1': array([1.]),\n",
       " 'split2_train_F1': array([1.]),\n",
       " 'split3_train_F1': array([1.]),\n",
       " 'split4_train_F1': array([1.]),\n",
       " 'split5_train_F1': array([1.]),\n",
       " 'split6_train_F1': array([1.]),\n",
       " 'split7_train_F1': array([1.]),\n",
       " 'split8_train_F1': array([1.]),\n",
       " 'split9_train_F1': array([1.]),\n",
       " 'mean_train_F1': array([1.]),\n",
       " 'std_train_F1': array([0.]),\n",
       " 'split0_test_Precision': array([0.44444444]),\n",
       " 'split1_test_Precision': array([0.53333333]),\n",
       " 'split2_test_Precision': array([0.57894737]),\n",
       " 'split3_test_Precision': array([0.66666667]),\n",
       " 'split4_test_Precision': array([0.625]),\n",
       " 'split5_test_Precision': array([0.52941176]),\n",
       " 'split6_test_Precision': array([0.42105263]),\n",
       " 'split7_test_Precision': array([0.52380952]),\n",
       " 'split8_test_Precision': array([0.64285714]),\n",
       " 'split9_test_Precision': array([0.6]),\n",
       " 'mean_test_Precision': array([0.5565441]),\n",
       " 'std_test_Precision': array([0.07744383]),\n",
       " 'rank_test_Precision': array([1], dtype=int32),\n",
       " 'split0_train_Precision': array([1.]),\n",
       " 'split1_train_Precision': array([1.]),\n",
       " 'split2_train_Precision': array([1.]),\n",
       " 'split3_train_Precision': array([1.]),\n",
       " 'split4_train_Precision': array([1.]),\n",
       " 'split5_train_Precision': array([1.]),\n",
       " 'split6_train_Precision': array([1.]),\n",
       " 'split7_train_Precision': array([1.]),\n",
       " 'split8_train_Precision': array([1.]),\n",
       " 'split9_train_Precision': array([1.]),\n",
       " 'mean_train_Precision': array([1.]),\n",
       " 'std_train_Precision': array([0.]),\n",
       " 'split0_test_Recall': array([0.47058824]),\n",
       " 'split1_test_Recall': array([0.47058824]),\n",
       " 'split2_test_Recall': array([0.64705882]),\n",
       " 'split3_test_Recall': array([0.58823529]),\n",
       " 'split4_test_Recall': array([0.58823529]),\n",
       " 'split5_test_Recall': array([0.52941176]),\n",
       " 'split6_test_Recall': array([0.47058824]),\n",
       " 'split7_test_Recall': array([0.64705882]),\n",
       " 'split8_test_Recall': array([0.52941176]),\n",
       " 'split9_test_Recall': array([0.52941176]),\n",
       " 'mean_test_Recall': array([0.54702462]),\n",
       " 'std_test_Recall': array([0.06485494]),\n",
       " 'rank_test_Recall': array([1], dtype=int32),\n",
       " 'split0_train_Recall': array([1.]),\n",
       " 'split1_train_Recall': array([1.]),\n",
       " 'split2_train_Recall': array([1.]),\n",
       " 'split3_train_Recall': array([1.]),\n",
       " 'split4_train_Recall': array([1.]),\n",
       " 'split5_train_Recall': array([1.]),\n",
       " 'split6_train_Recall': array([1.]),\n",
       " 'split7_train_Recall': array([1.]),\n",
       " 'split8_train_Recall': array([1.]),\n",
       " 'split9_train_Recall': array([1.]),\n",
       " 'mean_train_Recall': array([1.]),\n",
       " 'std_train_Recall': array([0.])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = np.array(grid_search_results['param_n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_auc = np.array(grid_search_results['rank_test_AUC'])\n",
    "rank_acc = np.array(grid_search_results['rank_test_Acc'])\n",
    "rank_f1 = np.array(grid_search_results['rank_test_F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = np.array(grid_search_results['mean_test_AUC'])\n",
    "accuracies = np.array(grid_search_results['mean_test_Acc'])\n",
    "f1s = np.array(grid_search_results['mean_test_F1'])\n",
    "precisions = np.array(grid_search_results['mean_test_Precision'])\n",
    "recalls = np.array(grid_search_results['mean_test_Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = np.array(grid_search_results['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graph_dir + '101418_can_delete/summ_table.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['dataset', 'kmer_size', 'n_splits', 'n_repeats', 'acc', 'auc', 'precision', 'recall', 'f1',\n",
    "                      'model', 'NMF_factors', 'params']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for i in range(len(aucs)):\n",
    "        param_grid = all_params[i]\n",
    "        criterion = param_grid[\"criterion\"]\n",
    "        max_depth = param_grid[\"max_depth\"]\n",
    "        max_features = param_grid[\"max_features\"]\n",
    "        min_samples_split = param_grid[\"min_samples_split\"]\n",
    "        n_estimators = param_grid[\"n_estimators\"]\n",
    "        n_jobs = 1\n",
    "        current_estimator = RandomForestClassifier(criterion=criterion, max_depth=max_depth, \n",
    "                                                max_features=max_features, min_samples_split=min_samples_split,\n",
    "                                                n_estimators=n_estimators,n_jobs=n_jobs)\n",
    "    \n",
    "    #results saved to csv\n",
    "\n",
    "        writer.writerow({\n",
    "                'dataset': str(data_set),\n",
    "                'kmer_size': kmer_size,\n",
    "                'n_splits': cv_gridsearch,\n",
    "                'n_repeats': n_iter_grid,\n",
    "                'acc': accuracies[i],\n",
    "                'auc': aucs[i],\n",
    "                'precision': precisions[i],\n",
    "                'recall': recalls[i],\n",
    "                'f1': f1s[i],\n",
    "                'model': learn_type,\n",
    "                'NMF_factors': n_factor,\n",
    "                'params': str(all_params[i])\n",
    "            })\n",
    "'''   \n",
    "print(\n",
    "        \">auroc:\" + str(aucs[i]) + \n",
    "        \" acc:\" + (str(accuracies[i]) + \n",
    "        \" f1:\" + (str(f1s[i]) +\n",
    "        \" recall:\" + str(recalls[i]) +\n",
    "        \" precision:\" + str(precisions[i]) +\n",
    "        \" dataset:\" + str(data_set) +\n",
    "        \" model:\" + learn_type +  \n",
    "        \" NMFfactors: \"+ str(n_factor) + \n",
    "        \" kmer_size:\" + str(kmer_size) + \n",
    "        #\" no_trees:\" + str(trees[i]))) +\n",
    "        \" params:\" + str(all_params[i])\n",
    "    )))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known_summ = pd.read_csv(graph_dir + '101418_can_delete/summ_table.csv')\n",
    "df_known_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LassoLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to help run it in jupyter #\n",
    "learn_type = 'lassoLR'\n",
    "cv_gridsearch = 10\n",
    "n_iter_grid = 20\n",
    "###\n",
    "\n",
    "param_grid = param_dict[learn_type]\n",
    "\n",
    "scoring = {\n",
    "    'Acc': 'accuracy',\n",
    "    'AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaHIT\n",
      "LOADED DATASET MetaHIT: 110 SAMPLES\n",
      "Qin_et_al\n",
      "LOADED DATASET Qin_et_al: 344 SAMPLES\n"
     ]
    }
   ],
   "source": [
    "kmer_size = 5\n",
    "n_factor = 5\n",
    "\n",
    "for data_set in data_sets_to_use:\n",
    "    data_set = data_set[0]\n",
    "        \n",
    "    # Retrieve diseased data and labels\n",
    "    allowed_labels = ['0', '1']\n",
    "    kmer_cnts, accessions, labelz, domain_labels = load_kmer_cnts_jf.load_kmers(kmer_size, data_set, allowed_labels)\n",
    "    print(\"LOADED DATASET \" + str(data_set[0]) + \": \" + str(len(kmer_cnts)) + \" SAMPLES\")\n",
    "    labelz=np.asarray(labelz).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [0, 5]:\n",
    "    if n == 0:\n",
    "        data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "        data_normalized, labels = shuffle(data_normalized, labelz, random_state=0) \n",
    "        x = data_normalized\n",
    "        y = labels\n",
    "                    \n",
    "    else:\n",
    "        data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "        data_normalized = stats_utils_AEB.NMF_factor(data_normalized, kmer_size, n_components = int(n), \n",
    "                                                     title=(str(data_set) + str(kmer_size) + \"mers\" \n",
    "                                                            + str(n) + \"factors\"))\n",
    "        data_normalized, labels = shuffle(data_normalized, labelz, random_state=0)\n",
    "        x = data_normalized\n",
    "        y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=cv_gridsearch, n_repeats=n_iter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_auc = LogisticRegressionCV(cv = k_fold, penalty = 'l1', scoring='roc_auc', solver = 'saga', n_jobs = 1).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_acc = LogisticRegressionCV(cv = k_fold, penalty = 'l1', scoring='accuracy', solver = 'saga', n_jobs = 1).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/pollard/home/abustion/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "estimator_acc = LogisticRegressionCV(cv = k_fold, penalty = 'l1', scoring='f1', solver = 'saga', n_jobs = 1).fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = estimator_auc.scores_[1].mean(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = estimator_acc.scores_[1].mean(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">auroc:0.6580728565936177 acc:0.6049537815126055 dataset:['Qin_et_al'] model:rf NMFfactors: 5 kmer_size:5 params:saga\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        \">auroc:\" + str(auc) + \n",
    "        \" acc:\" + str(acc) + \n",
    "        \" dataset:\" + str(data_set) +\n",
    "        \" model:\" + learn_type +  \n",
    "        \" NMFfactors: \"+ str(n_factor) + \n",
    "        \" kmer_size:\" + str(kmer_size) + \n",
    "        #\" no_trees:\" + str(trees[i]))) +\n",
    "        \" params:\" + str('saga')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir + '121018_can_delete/summ_table.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['dataset', 'kmer_size', 'n_splits', 'n_repeats', 'acc', 'auc', 'precision', 'recall', 'f1',\n",
    "                                  'model', 'NMF_factors', 'params']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    #results saved to csv\n",
    "\n",
    "    writer.writerow({\n",
    "                'dataset': str(data_set),\n",
    "                'kmer_size': kmer_size,\n",
    "                'n_splits': cv_gridsearch,\n",
    "                'n_repeats': n_iter_grid,\n",
    "                'acc': acc,\n",
    "                'auc': auc,\n",
    "                'model': learn_type,\n",
    "                'NMF_factors': n_factor,\n",
    "                'params': 'saga'\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">auroc:0.5 acc:0.77 f1:0.0021818181818181823 recall:0.005454545454545455 precision:0.0013636363636363637 dataset:['MetaHIT'] model:lassoLR NMFfactors: 5 kmer_size:5 params:{'penalty': 'l1', 'solver': 'saga'}\n",
      ">auroc:0.5 acc:0.7727272727272727 f1:0.0 recall:0.0 precision:0.0 dataset:['MetaHIT'] model:lassoLR NMFfactors: 5 kmer_size:5 params:{'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#save best models\n",
    "for i in range(len(aucs)):\n",
    "    param_grid = all_params[i]\n",
    "    n_jobs = 1\n",
    "    solver = param_grid[\"solver\"]\n",
    "    penalty = param_grid[\"penalty\"]\n",
    "    current_estimator = LogisticRegression(solver=solver, penalty=penalty, n_jobs=n_jobs)\n",
    "        \n",
    "    print(\n",
    "        \">auroc:\" + str(aucs[i]) + \n",
    "        \" acc:\" + (str(accuracies[i]) + \n",
    "        \" f1:\" + (str(f1s[i]) +\n",
    "        \" recall:\" + str(recalls[i]) +\n",
    "        \" precision:\" + str(precisions[i]) +\n",
    "        \" dataset:\" + str(data_set) +\n",
    "        \" model:\" + learn_type +  \n",
    "        \" NMFfactors: \"+ str(n_factor) + \n",
    "        \" kmer_size:\" + str(kmer_size) + \n",
    "        #\" no_trees:\" + str(trees[i]))) +\n",
    "        \" params:\" + str(all_params[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With LassoCV instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to help run it in jupyter #\n",
    "learn_type = 'lassoLR'\n",
    "cv_gridsearch = 10\n",
    "n_iter_grid = 1\n",
    "###\n",
    "\n",
    "param_grid = param_dict[learn_type]\n",
    "\n",
    "scoring = {\n",
    "    'Acc': 'accuracy',\n",
    "    'AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaHIT\n",
      "LOADED DATASET MetaHIT: 110 SAMPLES\n"
     ]
    }
   ],
   "source": [
    "kmer_size = 5\n",
    "n_factor = 25\n",
    "\n",
    "for data_set in data_sets_to_use:\n",
    "    data_set = data_set[0]\n",
    "        \n",
    "    # Retrieve diseased data and labels\n",
    "    allowed_labels = ['0', '1']\n",
    "    kmer_cnts, accessions, labelz, domain_labels = load_kmer_cnts_jf.load_kmers(kmer_size, data_set, allowed_labels)\n",
    "    print(\"LOADED DATASET \" + str(data_set[0]) + \": \" + str(len(kmer_cnts)) + \" SAMPLES\")\n",
    "    labelz=np.asarray(labelz).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [0, 25]:\n",
    "    if n == 0:\n",
    "        data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "        data_normalized, labels = shuffle(data_normalized, labelz, random_state=0) \n",
    "        x = data_normalized\n",
    "        y = labels\n",
    "                    \n",
    "    else:\n",
    "        data_normalized = normalize(kmer_cnts, axis = 1, norm = 'l1')\n",
    "        data_normalized = stats_utils_AEB.NMF_factor(data_normalized, kmer_size, n_components = int(n), \n",
    "                                                     title=(str(data_set) + str(kmer_size) + \"mers\" \n",
    "                                                            + str(n) + \"factors\"))\n",
    "        data_normalized, labels = shuffle(data_normalized, labelz, random_state=0)\n",
    "        x = data_normalized\n",
    "        y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = param_dict[learn_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'Acc': 'accuracy',\n",
    "    'AUC': 'roc_auc',\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = RepeatedStratifiedKFold(n_splits=cv_gridsearch, n_repeats=n_iter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegressionCV(penalty = 'l1', solver = 'saga', cv = k_fold, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n",
       "           cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x7faeb4f57048>,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "           random_state=None, refit=True, scoring='roc_auc', solver='saga',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.59259259, 0.44444444, 0.40740741, 0.44444444],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.62962963, 0.62962963, 0.62962963, 0.62962963],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.51851852, 0.44444444, 0.44444444, 0.40740741],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.81481481, 0.7037037 , 0.77777778, 0.77777778],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.62962963, 0.81481481, 0.81481481, 0.77777778],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.5       , 1.        , 1.        , 1.        ],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.3125    , 0.625     , 0.6875    , 0.6875    ],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.5       , 0.75      , 0.8125    , 0.875     ],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.5625    , 0.625     , 0.625     , 0.625     ],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "         0.5       , 0.6875    , 0.75      , 0.75      , 0.75      ]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
