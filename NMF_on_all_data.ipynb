{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pollard/home/abustion/deep_learning_microbiome/scripts/stats_utils_AEB.py:2: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('Agg') # this suppresses the console for plotting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from itertools import cycle, product\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold, train_test_split\n",
    "#from sklearn import cross_validation, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# import private scripts\n",
    "import load_kmer_cnts_jf\n",
    "import stats_utils_AEB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading all data before NMF, and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros(shape=(0,(int(4**kmer_size / 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaHIT\n",
      "LOADED DATASET MetaHIT: 110 SAMPLES\n",
      "(110, 8192)\n",
      "Qin_et_al\n",
      "LOADED DATASET Qin_et_al: 344 SAMPLES\n",
      "(454, 8192)\n",
      "Zeller_2014\n",
      "LOADED DATASET Zeller_2014: 121 SAMPLES\n",
      "(575, 8192)\n",
      "LiverCirrhosis\n",
      "LOADED DATASET LiverCirrhosis: 232 SAMPLES\n",
      "(807, 8192)\n",
      "Karlsson_2013_no_adapter\n",
      "LOADED DATASET Karlsson_2013_no_adapter: 96 SAMPLES\n",
      "(903, 8192)\n",
      "RA_no_adapter\n",
      "LOADED DATASET RA_no_adapter: 232 SAMPLES\n",
      "(1135, 8192)\n",
      "LeChatelier\n",
      "LOADED DATASET LeChatelier: 252 SAMPLES\n",
      "(1387, 8192)\n",
      "Feng\n",
      "LOADED DATASET Feng: 156 SAMPLES\n",
      "(1543, 8192)\n"
     ]
    }
   ],
   "source": [
    "data_sets_to_use = [\n",
    "    [['MetaHIT'], ['MetaHIT']],\n",
    "    [['Qin_et_al'], ['Qin_et_al']],\n",
    "    [['Zeller_2014'], ['Zeller_2014']],\n",
    "    [['LiverCirrhosis'], ['LiverCirrhosis']],\n",
    "    [['Karlsson_2013_no_adapter'], ['Karlsson_2013_no_adapter']],\n",
    "    [['RA_no_adapter'], ['RA_no_adapter']],\n",
    "    [['LeChatelier'], ['LeChatelier']],\n",
    "    [['Feng'], ['Feng']]\n",
    "   ]\n",
    "\n",
    "for data_set in data_sets_to_use:\n",
    "    data_set = data_set[0]\n",
    "    allowed_labels = ['0', '1']\n",
    "    kmer_cnts, accessions, labelz, domain_labels = load_kmer_cnts_jf.load_kmers(kmer_size,\n",
    "                                                                            data_set,\n",
    "                                                                            allowed_labels)\n",
    "\n",
    "    print(\"LOADED DATASET \" + str(data_set[0]) + \": \" + str(len(kmer_cnts)) + \" SAMPLES\")\n",
    "    labelz=np.asarray(labelz)\n",
    "    labelz=labelz.astype(np.int)\n",
    "    \n",
    "    data = np.append(data, kmer_cnts, axis=0)\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle(\"/pollard/home/abustion/deep_learning_microbiome/data_AEB/NMF_on_all_data/before_NMF_no_norm.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = normalize(data, axis = 1, norm = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized_df = pd.DataFrame(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized_df.to_pickle(\"/pollard/home/abustion/deep_learning_microbiome/data_AEB/NMF_on_all_data/before_NMF_with_norm.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying NMF and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "factors = 30\n",
    "for n in range(2, factors + 1):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-bd7b4b177906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     data_NMF = stats_utils_AEB.NMF_factor(data, kmer_size, n_components = int(n), \n\u001b[1;32m      4\u001b[0m                                                      title=(\"ALL_DATA_no_norm_\" + str(kmer_size) + \"mers\" \n\u001b[0;32m----> 5\u001b[0;31m                                                             + str(n) + \"factors\"))\n\u001b[0m",
      "\u001b[0;32m~/deep_learning_microbiome/scripts/stats_utils_AEB.py\u001b[0m in \u001b[0;36mNMF_factor\u001b[0;34m(data, kmer_size, n_components, init, solver, beta_loss, max_iter, random_state, title)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m#NMF matrixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             shuffle=self.shuffle)\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         self.reconstruction_err_ = _beta_divergence(X, W, H, self.beta_loss,\n",
      "\u001b[0;32m~/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                                   \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                                                   \u001b[0ml2_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                                                   verbose)\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36m_fit_multiplicative_update\u001b[0;34m(X, W, H, beta_loss, max_iter, tol, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose)\u001b[0m\n\u001b[1;32m    789\u001b[0m         delta_W, H_sum, HHt, XHt = _multiplicative_update_w(\n\u001b[1;32m    790\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             H_sum, HHt, XHt, update_H)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mdelta_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36m_multiplicative_update_w\u001b[0;34m(X, W, H, beta_loss, l1_reg_W, l2_reg_W, gamma, H_sum, HHt, XHt, update_H)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# Numerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mXHt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mXHt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;31m# avoid a copy of XHt, which will be re-computed (update_H=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_1118/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "factors=30\n",
    "for n in range(2, factors + 1):\n",
    "    data_NMF = stats_utils_AEB.NMF_factor(data, kmer_size, n_components = int(n), \n",
    "                                                     title=(\"ALL_DATA_no_norm_\" + str(kmer_size) + \"mers\" \n",
    "                                                            + str(n) + \"factors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors=30\n",
    "for n in range(2, factors + 1):\n",
    "    data_NMF = stats_utils_AEB.NMF_factor(data_normalized, kmer_size, n_components = int(n), \n",
    "                                                     title=(\"ALL_DATA_with_norm_\" + str(kmer_size) + \"mers\" \n",
    "                                                            + str(n) + \"factors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
