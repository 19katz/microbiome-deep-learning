{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#~/miniconda3/bin/python3\n",
    "\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import ntpath\n",
    "\n",
    "from Bio import SeqIO\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import config_file\n",
    "\n",
    "species_directory = config_file.species_directory\n",
    "data_directory = config_file.data_directory\n",
    "analysis_directory = config_file.analysis_directory  \n",
    "scripts_directory = config_file.scripts_directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets_to_use = [\n",
    "    [['MetaHIT'], ['MetaHIT']],\n",
    "    [['Qin_et_al'], ['Qin_et_al']],\n",
    "    [['Zeller_2014'], ['Zeller_2014']],\n",
    "    [['LiverCirrhosis'], ['LiverCirrhosis']]\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_species(data_sets):\n",
    "    \n",
    "    for data_set in data_sets:\n",
    "        print(data_set)\n",
    "\n",
    "        if data_set == \"MetaHIT\":\n",
    "            cnts = pd.read_csv(species_directory + 'MetaHIT_ids.spcsAbundance.noNA.txt', sep = '\\t')\n",
    "            df_labels = pd.read_csv(data_directory + \"metadata/MetaHIT_ids.txt\", sep = '\\t')\n",
    "            labels = df_labels[['subject_id', 'ibd']]\n",
    "            ids = labels['subject_id'].str.replace('.', '_').str.replace('-', '_')\n",
    "            df_labels['subject_id'] = ids\n",
    "            labels = df_labels[['subject_id', 'ibd']].drop_duplicates().set_index(\"subject_id\")\n",
    "            intersection = pd.merge(labels, cnts, how='inner', left_index=True, right_index=True)\n",
    "            \n",
    "            labels = np.asarray(intersection['ibd']).astype(np.int)\n",
    "            \n",
    "            species = intersection.iloc[:,1:]\n",
    "            species_cnts = species.values\n",
    "            \n",
    "            features = list(species.columns)\n",
    "            \n",
    "            return species_cnts, labels, features\n",
    "\n",
    "        \n",
    "        elif data_set=='Qin_et_al':\n",
    "            cnts = pd.read_csv(species_directory + 'Qin_2012_ids_all.spcsAbundance.noNA.txt', sep = '\\t')\n",
    "            df_labels = pd.read_csv(data_directory + \"metadata/Qin_2012_ids_all.txt\", sep = '\\t')\n",
    "            labels = df_labels[['subject_id', 't2d']].drop_duplicates().set_index(\"subject_id\")\n",
    "            intersection = pd.merge(labels, cnts, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "            labels = np.asarray(intersection['t2d']).astype(np.int)\n",
    "            \n",
    "            species = intersection.iloc[:,1:]\n",
    "            species_cnts = species.values\n",
    "            \n",
    "            features = list(species.columns)\n",
    "            \n",
    "            return species_cnts, labels, features\n",
    "        \n",
    "        elif data_set=='Zeller_2014':\n",
    "            cnts = pd.read_csv(species_directory + 'Zeller.spcsAbundance.noNA.txt', sep = '\\t')\n",
    "            df_labels = pd.read_csv(data_directory + \"metadata/Zeller_metadata.txt\", sep = '\\t')\n",
    "            labels = df_labels[['Sample ID', 'Group']].drop_duplicates().set_index(\"Sample ID\")\n",
    "            labels['Group'] = labels['Group'].astype('category').cat.rename_categories(['1','0'])\n",
    "            intersection = pd.merge(labels, cnts, how='inner', left_index=True, right_index=True).dropna()\n",
    "            \n",
    "            labels = np.asarray(intersection['Group']).astype(np.int)\n",
    "            \n",
    "            species = intersection.iloc[:,1:]\n",
    "            species_cnts = species.values\n",
    "            \n",
    "            features = list(species.columns)\n",
    "            \n",
    "            return species_cnts, labels, features\n",
    "        \n",
    "        elif data_set=='LiverCirrhosis':\n",
    "            cnts = pd.read_csv(species_directory + 'LiverCirrhosis.spcsAbundance.noNA.txt', sep = '\\t')\n",
    "            df_labels = pd.read_csv(data_directory + \"metadata/LiverCirrhosis.txt\", sep = '\\t')\n",
    "            labels = df_labels[['Sample ID', 'Cirrhotic(Y or N)']].drop_duplicates().set_index(\"Sample ID\")\n",
    "            labels['Group'] = labels['Cirrhotic(Y or N)'].astype('category').cat.rename_categories(['0','1'])\n",
    "            labels = labels.drop(['Cirrhotic(Y or N)'], axis = 1)\n",
    "            intersection = pd.merge(labels, cnts, how='inner', left_index=True, right_index=True).dropna()\n",
    "            \n",
    "            labels = np.asarray(intersection['Group']).astype(np.int)\n",
    "            \n",
    "            species = intersection.iloc[:,1:]\n",
    "            species_cnts = species.values\n",
    "            \n",
    "            features = list(species.columns)\n",
    "            \n",
    "            return species_cnts, labels, features           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaHIT\n",
      "LOADED DATASET MetaHIT: 110 SAMPLES\n",
      "(110, 3302)\n",
      "(110,)\n",
      "3302 features\n",
      "\n",
      "Qin_et_al\n",
      "LOADED DATASET Qin_et_al: 271 SAMPLES\n",
      "(271, 3302)\n",
      "(271,)\n",
      "3302 features\n",
      "\n",
      "Zeller_2014\n",
      "LOADED DATASET Zeller_2014: 121 SAMPLES\n",
      "(121, 3302)\n",
      "(121,)\n",
      "3302 features\n",
      "\n",
      "LiverCirrhosis\n",
      "LOADED DATASET LiverCirrhosis: 232 SAMPLES\n",
      "(232, 3302)\n",
      "(232,)\n",
      "3302 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_set in data_sets_to_use:\n",
    "    data_set = data_set[0]\n",
    "    species_cnts, labelz, feats = load_species(data_set)\n",
    "    print(\"LOADED DATASET \" + str(data_set[0]) + \": \" + str(len(species_cnts)) + \" SAMPLES\")\n",
    "    print(species_cnts.shape)\n",
    "    print(labelz.shape)\n",
    "    print(str(len(feats)) + \" features\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
